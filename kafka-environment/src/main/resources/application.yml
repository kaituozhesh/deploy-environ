spring:
  kafka:
    bootstrap-servers: 192.168.181.136:9092 # 指定Kafka Server的地址，集群配多个，中间逗号隔开
    producer:
      retries: 0                # 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，当retries为0时，producer不会重复
      batch-size: 16384         # 每次批量发送消息的数量，producer积累到一定数量，一次发送
      buffer-memory: 33554432   # producer积累数据一次发送，缓存大小达到buffer money就发送数据
      acks: 1 # producer要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下
        # acks: 0   producer 不会等待服务器的反馈。该消息会被立刻添加到 socket buffer 中并认为已经发送完成。在这种情况下，服务器是否收到请求是没法保证的，并且参数retries也不会生效（因为客户端无法获得失败信息）。每个记录返回的 offset 总是被设置为-1。
        # acks: 1   leader节点会将记录写入本地日志，但无需等待所有follower节点反馈确认成功即可做出回应。在这种情况下，如果 leader 节点在接收记录之后，并且在 follower 节点复制数据完成之前产生错误，则这条记录会丢失
        # acks: all leader 节点会等待所有同步中的副本确认之后再确认这条记录是否发送完成。只要至少有一个同步副本存在，记录就不会丢失。这种方式是对请求传递的最有效保证。acks=-1与acks=all是等效的。
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer


    consumer:
      group-id: default_consumer_group  # 群组ID
      enable-auto-commit: true          # 是否自动提交offset
      auto-commit-interval: 1000        # 自动提交时间间隔 单位：毫秒 默认：5000
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer